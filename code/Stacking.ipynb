{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造stacking方法\n",
    "  我们写一个stacking方法，下面是它的实现代码：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 2 1 0 0 1 1 0 2 0 2 1 1 0 1 2 0 0 0 2 2 2 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "def get_stacking(clf, x_train, y_train, x_test, n_folds=10):\n",
    "    \"\"\"\n",
    "    这个函数是stacking的核心，使用交叉验证的方法得到次级训练集\n",
    "    x_train, y_train, x_test 的值应该为numpy里面的数组类型 numpy.ndarray .\n",
    "    如果输入为pandas的DataFrame类型则会把报错\"\"\"\n",
    "    train_num, test_num = x_train.shape[0], x_test.shape[0]\n",
    "    second_level_train_set = np.zeros((train_num,))\n",
    "    second_level_test_set = np.zeros((test_num,))\n",
    "    test_nfolds_sets = np.zeros((test_num, n_folds))\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "\n",
    "    for i,(train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "        x_tra, y_tra = x_train[train_index], y_train[train_index]\n",
    "        x_tst, y_tst =  x_train[test_index], y_train[test_index]\n",
    "\n",
    "        clf.fit(x_tra, y_tra)\n",
    "\n",
    "        second_level_train_set[test_index] = clf.predict(x_tst)\n",
    "        test_nfolds_sets[:,i] = clf.predict(x_test)\n",
    "\n",
    "    second_level_test_set[:] = test_nfolds_sets.mean(axis=1)\n",
    "    return second_level_train_set, second_level_test_set\n",
    "\n",
    "\n",
    "\n",
    "#我们这里使用5个分类算法，为了体现stacking的思想，就不加参数了\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "adb_model = AdaBoostClassifier()\n",
    "gdbc_model = GradientBoostingClassifier()\n",
    "et_model = ExtraTreesClassifier()\n",
    "svc_model = SVC()\n",
    "\n",
    "#在这里我们使用train_test_split来人为的制造一些数据\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris.data, iris.target, test_size=0.2)\n",
    "\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "for clf in [rf_model, adb_model, gdbc_model, et_model, svc_model]:\n",
    "    train_set, test_set = get_stacking(clf, train_x, train_y, test_x)\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "meta_train = np.concatenate([result_set.reshape(-1,1) for result_set in train_sets], axis=1)\n",
    "meta_test = np.concatenate([y_test_set.reshape(-1,1) for y_test_set in test_sets], axis=1)\n",
    "\n",
    "#使用决策树作为我们的次级分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(meta_train, train_y)\n",
    "df_predict = dt_model.predict(meta_test)\n",
    "\n",
    "print(df_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造stacking类\n",
    "事实上还可以构造一个stacking的类，它拥有fit和predict方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "import numpy as np\n",
    "#对于分类问题可以使用 ClassifierMixin\n",
    "\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    # 我们将原来的模型clone出来，并且进行实现fit功能\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "\n",
    "        #对于每个模型，使用交叉验证的方法来训练初级学习器，并且得到次级训练集\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance = clone(model)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "\n",
    "        # 使用次级训练集来训练次级学习器\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "\n",
    "    #在上面的fit方法当中，我们已经将我们训练出来的初级学习器和次级学习器保存下来了\n",
    "    #predict的时候只需要用这些学习器构造我们的次级预测数据集并且进行预测就可以了\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
